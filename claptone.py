# -*- coding: utf-8 -*-
"""ClapTone

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EQfqzzwudwLyJQThFxbLfFHMDNsBeS48

# Library Setup
"""

# !pip install pretty_midi
# !sudo apt install -y fluidsynth
# !pip install --upgrade pyfluidsynth

import numpy as np
import tensorflow as tf
import pandas as pd
import collections
import fluidsynth
# import glob
import pretty_midi
from IPython import display
from typing import Dict, List, Optional, Sequence, Tuple
import os
from matplotlib import pyplot as plt

generated_notes = []
filenames = []
train_ds = None
model = None
key_order = ["pitch" , "step" , "duration"]
"""# MIDI Setup

"""
def midiSetup():
  global filenames
  dir_path = "/content/"
  filenames = next(os.walk(dir_path), (None, None, []))[2]  # [] if no file
  print(filenames)
  filenames = [dir_path+"/"+s for s in filenames]

def plot_piano_roll(notes: pd.DataFrame, count: Optional[int] = None):
  if count:
    title = f'First {count} notes'
  else:
    title = f'Whole track'
    count = len(notes['pitch'])
  plt.figure(figsize=(20, 4))
  plot_pitch = np.stack([notes['pitch'], notes['pitch']], axis=0)
  plot_start_stop = np.stack([notes['start'], notes['end']], axis=0)
  plt.plot(
      plot_start_stop[:, :count], plot_pitch[:, :count], color="b", marker=".")
  plt.xlabel('Time [s]')
  plt.ylabel('Pitch')
  _ = plt.title(title)

sample_file = filenames[33]
def midi_to_notes(midi_file):
    pm = pretty_midi.PrettyMIDI(midi_file)
    instrument = pm.instruments[0]
    notes = collections.defaultdict(list)
    sorted_notes = sorted(instrument.notes , key=lambda note:note.start)
    prev_start = sorted_notes[0].start

    for note in sorted_notes:
        start = note.start
        end = note.end
        notes["pitch"].append(note.pitch)
        notes["start"].append(start)
        notes["end"].append(end)
        notes["step"].append(start - prev_start)
        notes["duration"].append(end - start)
        prev_start = start
    return pd.DataFrame({name:np.array(value) for name,value in notes.items()})

raw_notes = midi_to_notes(sample_file)
print(raw_notes)
note_names = np.vectorize(pretty_midi.note_number_to_name)
sample_note_names = note_names(raw_notes["pitch"])
plot_piano_roll(raw_notes)

"""# Train"""
def train():
  global train_ds
  num_files = 5
  all_notes = []
  for f in filenames[:num_files] :
      notes = midi_to_notes(f)
      all_notes.append(notes)
  all_notes = pd.concat(all_notes)
  print(all_notes)
  train_notes = np.stack([all_notes[key] for key in key_order] , axis = 1)
  notes_ds=tf.data.Dataset.from_tensor_slices(train_notes)
  notes_ds.element_spec

  seq_length = 20
  vocab_size = 128
  def create_sequences(dataset,seq_length,vocab_size=128):
    sequences = []
    targets = []
    num_seq = train_notes.shape[0] - seq_length
    for i in range(num_seq):
      sequence = train_notes[i:i+seq_length - 1,:] / [vocab_size, 1 ,1]
      target = train_notes[i+seq_length] / vocab_size
      sequences.append(sequence)
      targets.append(target)
    sequences = np.array(sequences)
    targets = np.array(targets)
    print(sequences.shape , targets.shape)
    dataset = tf.data.Dataset.from_tensor_slices((sequences,{"pitch":targets[:,0] , "step":targets[:,1] ,"duration" :targets[:,2]}))
    return dataset
  seq_ds = create_sequences(notes_ds, 21, vocab_size)
  batch_size =64
  buffer_size = 5000
  train_ds = seq_ds.shuffle(buffer_size).batch(batch_size)
  train_ds.element_spec

def createModel():
  global model
  layer = tf.keras.layers
  learning_rate = 0.005
  input_data = tf.keras.Input(shape=(seq_length , 3))
  x= layer.LSTM(128)(input_data)
  outputs = {
    "pitch":tf.keras.layers.Dense(64 , name = "pitch")(x),
    "step":tf.keras.layers.Dense(1 , name = "step")(x),
    "duration":tf.keras.layers.Dense(1 , name = "duration")(x),
  }
  model = tf.keras.Model(input_data , outputs)

  loss ={
    "pitch" : tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),
    "step": tf.keras.losses.MeanSquaredError(),
    "duration":tf.keras.losses.MeanSquaredError(),
  }
  optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)
  model.compile(loss=loss , loss_weights={
      'pitch': 0.05,
      'step': 1.0,
      'duration':1.0,
    }, optimizer = optimizer)

  model.summary()
  def fitModel():
    epochs = 10

    history = model.fit(
        train_ds,
        epochs=epochs,
    )

    plt.plot(history.epoch, history.history['loss'], label='total loss')
    plt.show()

  fitModel()
# Commented out IPython magic to ensure Python compatibility.


"""# Run the model"""
def createPrediction():
  def predict_next_note(
  notes , keras_model , temperature):

    global generated_notes
    assert temperature > 0
    inputs = np.expand_dims(notes , 0)
    predictions = model.predict(inputs)
    pitch_logits = predictions['pitch']
    step = predictions["step"]
    duration = predictions["duration"]
    pitch_logits /= temperature
    pitch = tf.random.categorical(pitch_logits , num_samples = 1)
    pitch = tf.squeeze(pitch , axis = -1)
    duration = tf.squeeze(duration , axis =-1)
    step = tf.squeeze(step,axis = -1)
    step = tf.maximum(0,step)
    duration = tf.maximum(0 , duration)
    return int(pitch) , float(step) , float(duration)

  temperature = 2.0
  num_predictions = 120
  seq_length = 20
  vocab_size= 128
  sample_notes = np.stack([raw_notes[key] for key in key_order], axis=1)

  # The initial sequence of notes and the pitch is normalized similar to training sequences
  input_notes = (
    sample_notes[:seq_length] / np.array([vocab_size, 1, 1]))

  generated_notes = []
  prev_start = 0
  for _ in range(num_predictions):
    pitch, step, duration = predict_next_note(input_notes, model, temperature)
    start = prev_start + step
    end = start + duration
    input_note = (pitch, step, duration)
    generated_notes.append((*input_note, start, end))
    input_notes = np.delete(input_notes, 0, axis=0)
    input_notes = np.append(input_notes, np.expand_dims(input_note, 0), axis=0)
    prev_start = start

  generated_notes = pd.DataFrame(
    generated_notes, columns=(*key_order, 'start', 'end'))

"""# Create MIDI File"""

sampling_rate = 16000
def display_audio(pm, seconds=30):
	waveform = pm.fluidsynth(fs=sampling_rate)
# Take a sample of the generated waveform to mitigate kernel resets
	waveform_short = waveform[:seconds*sampling_rate]
	return display.Audio(waveform_short, rate=sampling_rate)

def notes_to_midi(
  notes: pd.DataFrame,
  out_file: str,
  instrument_name: str,
  velocity: int = 100, # note loudness
  ) -> pretty_midi.PrettyMIDI:

  pm = pretty_midi.PrettyMIDI()
  instrument = pretty_midi.Instrument(
    program=pretty_midi.instrument_name_to_program(
      instrument_name))

  prev_start = 0
  for i, note in notes.iterrows():
    start = float(prev_start + note['step'])
    end = float(start + note['duration'])
    note = pretty_midi.Note(
      velocity=velocity,
      pitch=int(note['pitch']),
      start=start,
      end=end,
    )
    instrument.notes.append(note)
    prev_start = start

  pm.instruments.append(instrument)
  pm.write(out_file)
  display.display(display_audio(pm))
  return pm

# notes_to_midi(generated_notes,"w.mid","Electric Grand Piano")

